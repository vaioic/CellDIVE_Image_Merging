{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ad4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioio import BioImage\n",
    "from bioio_ome_zarr.writers import Channel, OMEZarrWriter\n",
    "import dask.array as da\n",
    "from zarr.codecs import BloscCodec\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import Dict, List, Union\n",
    "from collections import defaultdict\n",
    "from Group_Files import group_ome_tiff_by_region, print_group_summary,extract_channel_marker_info,print_channel_marker_info\n",
    "import tempfile\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9ce9a",
   "metadata": {},
   "source": [
    "## Testing file grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to group OME-TIFF image files by region identifier.\n",
    "\n",
    "This module provides functionality to parse and group image files following\n",
    "the naming convention:\n",
    "prefix_mmddyyyy_S#_[1-15].0.4_R###_(channel)_(marker)_FINAL_suffix.ome.tif\n",
    "\"\"\"\n",
    "\n",
    "def group_ome_tiff_by_region(\n",
    "    directory: Union[str, Path],\n",
    "    return_type: str = \"dict\"\n",
    ") -> Union[Dict[str, List[str]], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Group OME-TIFF files by their region identifier (R###).\n",
    "    \n",
    "    This function searches for files matching the specified naming convention\n",
    "    and groups them by their region identifier. Only files containing 'FINAL'\n",
    "    in their name are included.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str or Path\n",
    "        Path to the directory containing the OME-TIFF files\n",
    "    return_type : str, optional\n",
    "        Format of the return value. Either \"dict\" (default) or \"list\"\n",
    "        - \"dict\": Returns a dictionary with region IDs as keys\n",
    "        - \"list\": Returns a list of lists, one per region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict or list\n",
    "        If return_type=\"dict\": Dictionary with region IDs (e.g., \"R001\") as keys\n",
    "            and lists of file paths as values\n",
    "        If return_type=\"list\": List of lists, where each inner list contains\n",
    "            file paths for one region\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get groups as dictionary\n",
    "    >>> groups = group_ome_tiff_by_region(\"/path/to/images\", return_type=\"dict\")\n",
    "    >>> print(groups.keys())\n",
    "    dict_keys(['R000', 'R001', 'R002', ...])\n",
    "    \n",
    "    >>> # Get groups as list of lists\n",
    "    >>> groups = group_ome_tiff_by_region(\"/path/to/images\", return_type=\"list\")\n",
    "    >>> print(f\"Found {len(groups)} regions\")\n",
    "    Found 8 regions\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The regex pattern matches files with this structure:\n",
    "    - prefix: any characters (typically initials)\n",
    "    - date: mmddyyyy format\n",
    "    - sample: S followed by 1-2 digits (S1-S15)\n",
    "    - round: integer 1-15, followed by .0.4\n",
    "    - region: R followed by 3 digits (R000-R999)\n",
    "    - channel: DAPI, Cy3, Cy5, FITC, or Cy7\n",
    "    - marker: alphanumeric name\n",
    "    - must contain 'FINAL'\n",
    "    - suffix: AFR_F or _F\n",
    "    - extension: .ome.tif\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to Path object for easier handling\n",
    "    directory = Path(directory)\n",
    "    \n",
    "    if not directory.exists():\n",
    "        raise ValueError(f\"Directory does not exist: {directory}\")\n",
    "    \n",
    "    if not directory.is_dir():\n",
    "        raise ValueError(f\"Path is not a directory: {directory}\")\n",
    "    \n",
    "    # Regex pattern to match the file naming convention\n",
    "    # Pattern breakdown:\n",
    "    # ^(.+?)_ : prefix (non-greedy) followed by underscore\n",
    "    # (\\d{8})_ : date in mmddyyyy format\n",
    "    # (S\\d{1,2})_ : sample ID (S1 to S15)\n",
    "    # (\\d{1,2}\\.0\\.\\d+)_ : round number (1-15.0.4)\n",
    "    # (R\\d{3})_ : region identifier (R###)\n",
    "    # (DAPI|Cy3|Cy5|FITC|Cy7)_ : channel name\n",
    "    # ([A-Za-z0-9_]+)_ : marker name\n",
    "    # .*FINAL.* : must contain FINAL\n",
    "    # (AFR_F|_F) : suffix\n",
    "    # \\.ome\\.tif$ : file extension\n",
    "    \n",
    "    pattern = re.compile(\n",
    "        r'^(.+?)_'           # prefix\n",
    "        r'(\\d{8})_'          # date (mmddyyyy)\n",
    "        r'(S\\d{1,2})_'       # sample ID (S1-S15)\n",
    "        r'(\\d{1,2}\\.\\d+\\.\\d+)_'  # round (e.g., 1.0.1, 1.0.4, 15.0.4)\n",
    "        r'(R\\d{3})_'         # region (R###)\n",
    "        r'(DAPI|Cy3|Cy5|FITC|Cy7|FITC)_'  # channel name\n",
    "        r'(.+?)_'            # marker name (non-greedy)\n",
    "        r'.*FINAL.*'         # must contain FINAL\n",
    "        r'(AFR_F|_F)'        # suffix\n",
    "        r'\\.ome\\.tif$',      # extension\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store grouped files\n",
    "    region_groups = defaultdict(list)\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for file_path in directory.iterdir():\n",
    "        # Skip if not a file\n",
    "        if not file_path.is_file():\n",
    "            continue\n",
    "        \n",
    "        filename = file_path.name\n",
    "        \n",
    "        # Check if filename matches the pattern\n",
    "        match = pattern.match(filename)\n",
    "        \n",
    "        if match:\n",
    "            # Extract the region identifier (5th capture group)\n",
    "            region_id = match.group(5)\n",
    "            \n",
    "            # Add the full file path to the corresponding region group\n",
    "            region_groups[region_id].append(str(file_path))\n",
    "    \n",
    "    # Sort files within each group for consistent ordering\n",
    "    for region_id in region_groups:\n",
    "        region_groups[region_id].sort()\n",
    "    \n",
    "    # Return based on requested format\n",
    "    if return_type == \"dict\":\n",
    "        # Return as regular dict (sorted by region ID)\n",
    "        return dict(sorted(region_groups.items()))\n",
    "    elif return_type == \"list\":\n",
    "        # Return as list of lists (sorted by region ID)\n",
    "        return [region_groups[region_id] for region_id in sorted(region_groups.keys())]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_type: {return_type}. Must be 'dict' or 'list'\")\n",
    "\n",
    "\n",
    "def print_group_summary(groups: Union[Dict[str, List[str]], List[List[str]]]) -> None:\n",
    "    \"\"\"\n",
    "    Print a summary of the grouped files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    groups : dict or list\n",
    "        The output from group_ome_tiff_by_region()\n",
    "    \"\"\"\n",
    "    if isinstance(groups, dict):\n",
    "        print(f\"Found {len(groups)} region groups:\")\n",
    "        for region_id, files in groups.items():\n",
    "            print(f\"\\n{region_id}: {len(files)} files\")\n",
    "            for file_path in files:\n",
    "                print(f\"  - {Path(file_path).name}\")\n",
    "    elif isinstance(groups, list):\n",
    "        print(f\"Found {len(groups)} region groups:\")\n",
    "        for i, files in enumerate(groups):\n",
    "            print(f\"\\nGroup {i+1}: {len(files)} files\")\n",
    "            for file_path in files:\n",
    "                print(f\"  - {Path(file_path).name}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    # Example 1: Get groups as dictionary\n",
    "    if len(sys.argv) > 1:\n",
    "        directory = sys.argv[1]\n",
    "    else:\n",
    "        directory = \"/mnt/user-data/uploads\"  # Default to uploaded files\n",
    "    \n",
    "    print(f\"Searching for OME-TIFF files in: {directory}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Get groups as dictionary\n",
    "        groups_dict = group_ome_tiff_by_region(directory, return_type=\"dict\")\n",
    "        print_group_summary(groups_dict)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\\nExample: Accessing files from a specific region:\")\n",
    "        if groups_dict:\n",
    "            first_region = list(groups_dict.keys())[0]\n",
    "            print(f\"\\nFiles in region {first_region}:\")\n",
    "            for file_path in groups_dict[first_region]:\n",
    "                print(f\"  {Path(file_path).name}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\\nAlternative: Get groups as list of lists:\")\n",
    "        groups_list = group_ome_tiff_by_region(directory, return_type=\"list\")\n",
    "        print(f\"Total number of region groups: {len(groups_list)}\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada40c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test script to demonstrate the grouping function with example filenames\n",
    "from the uploaded image.\n",
    "\"\"\"\n",
    "\n",
    "# Create example filenames based on the uploaded image\n",
    "example_filenames = [\n",
    "    \"KK_10082025_S2_1.0.1_R000_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R000_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R001_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R001_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R002_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R002_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R003_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R003_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R004_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R004_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R005_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R005_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R006_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R006_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R007_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R007_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R000_Cy3_iba1_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R000_Cy5_Neun_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R000_DAPI_FINAL_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R000_FITC_GFAP_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R001_Cy3_iba1_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R001_Cy5_Neun_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R001_DAPI_FINAL_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R001_FITC_GFAP_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R002_Cy3_iba1_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R002_Cy5_Neun_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R002_DAPI_FINAL_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R002_FITC_GFAP_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R003_Cy3_iba1_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R003_Cy5_Neun_FINAL_AFR_F.ome.tif\",\n",
    "]\n",
    "\n",
    "# Create a temporary directory and create empty files\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    print(f\"Creating test files in: {tmpdir}\\n\")\n",
    "    \n",
    "    # Create the test files\n",
    "    for filename in example_filenames:\n",
    "        filepath = Path(tmpdir) / filename\n",
    "        filepath.touch()\n",
    "    \n",
    "    print(f\"Created {len(example_filenames)} test files\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Test the grouping function with dictionary return type\n",
    "    print(\"\\n### TEST 1: Dictionary Return Type ###\\n\")\n",
    "    groups_dict = group_ome_tiff_by_region(tmpdir, return_type=\"dict\")\n",
    "    print_group_summary(groups_dict)\n",
    "    \n",
    "    # Show statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n### Statistics ###\")\n",
    "    print(f\"Total regions found: {len(groups_dict)}\")\n",
    "    for region_id, files in groups_dict.items():\n",
    "        print(f\"  {region_id}: {len(files)} files\")\n",
    "    \n",
    "    # Test with list return type\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n### TEST 2: List Return Type ###\\n\")\n",
    "    groups_list = group_ome_tiff_by_region(tmpdir, return_type=\"list\")\n",
    "    print(f\"Number of region groups: {len(groups_list)}\")\n",
    "    for i, group in enumerate(groups_list):\n",
    "        print(f\"\\nGroup {i+1}: {len(group)} files\")\n",
    "        for filepath in group[:3]:  # Show first 3 files\n",
    "            print(f\"  - {Path(filepath).name}\")\n",
    "        if len(group) > 3:\n",
    "            print(f\"  ... and {len(group) - 3} more files\")\n",
    "    \n",
    "    # Example: Process each group\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n### Example: Processing Each Group ###\\n\")\n",
    "    for region_id, file_list in groups_dict.items():\n",
    "        print(f\"Processing region {region_id}:\")\n",
    "        print(f\"  - Found {len(file_list)} files\")\n",
    "        \n",
    "        # Example: Extract channel information\n",
    "        channels = set()\n",
    "        for filepath in file_list:\n",
    "            filename = Path(filepath).name\n",
    "            if \"DAPI\" in filename:\n",
    "                channels.add(\"DAPI\")\n",
    "            elif \"Cy3\" in filename:\n",
    "                channels.add(\"Cy3\")\n",
    "            elif \"Cy5\" in filename:\n",
    "                channels.add(\"Cy5\")\n",
    "            elif \"FITC\" in filename:\n",
    "                channels.add(\"FITC\")\n",
    "            elif \"Cy7\" in filename:\n",
    "                channels.add(\"Cy7\")\n",
    "        \n",
    "        print(f\"  - Channels present: {sorted(channels)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c88e42",
   "metadata": {},
   "source": [
    "## Testing reading in groups and merging into one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58dbf036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 region groups:\n",
      "\n",
      "R000: 6 files\n",
      "  - CG_10092025_S1_1.0.4_R000_Cy3_sLeX-AF594_FINAL_AFR_F.ome.tif\n",
      "  - CG_10092025_S1_1.0.4_R000_Cy5_ECad-AF647_FINAL_AFR_F.ome.tif\n",
      "  - CG_10092025_S1_1.0.4_R000_DAPI__FINAL_F.ome.tif\n",
      "  - CG_10092025_S1_1.0.4_R000_FITC_VVL-488_FINAL_AFR_F.ome.tif\n",
      "  - CG_10092025_S1_2.0.4_R000_Cy5_VIM-AF647_FINAL_AFR_F.ome.tif\n",
      "  - CG_10092025_S1_2.0.4_R000_FITC_AAL-FITC_FINAL_AFR_F.ome.tif\n",
      "Found channel/marker info for 1 regions:\n",
      "\n",
      "R000: 6 channels\n",
      "  - 1.0.4_Cy3_sLeX-AF594\n",
      "  - 1.0.4_Cy5_ECad-AF647\n",
      "  - 1.0.4_DAPI\n",
      "  - 1.0.4_FITC_VVL-488\n",
      "  - 2.0.4_Cy5_VIM-AF647\n",
      "  - 2.0.4_FITC_AAL-FITC\n"
     ]
    }
   ],
   "source": [
    "test_dir = r'E:\\Cores\\CellDIVE_ImageMerging\\Testing_CellDVIE_Input\\Trial2_10102025'\n",
    "groups_dict = group_ome_tiff_by_region(test_dir)\n",
    "print_group_summary(groups_dict)\n",
    "channel_dict = extract_channel_marker_info(test_dir)\n",
    "print_channel_marker_info(channel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b856ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop set up for reading through multiple regions\n",
    "for region_id, files in groups_dict.items():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(groups_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23cd2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = groups_dict['R000']\n",
    "channels = channel_dict['R000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80cafb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dic = [Channel(label=f\"{i}\",color=\"FF0000\") for i in channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c7f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<bioio_ome_zarr.writers.metadata.Channel object at 0x000001AC78CBE4D0>, <bioio_ome_zarr.writers.metadata.Channel object at 0x000001AC78CBD9D0>, <bioio_ome_zarr.writers.metadata.Channel object at 0x000001AC78CBEDD0>, <bioio_ome_zarr.writers.metadata.Channel object at 0x000001AC78CBF490>, <bioio_ome_zarr.writers.metadata.Channel object at 0x000001AC78CBF050>, <bioio_ome_zarr.writers.metadata.Channel object at 0x000001AC78CD2E50>]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = files[0]\n",
    "test_img = BioImage(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bc1b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_channel = [Channel(label=channels[0],color=\"FF0000\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f50373f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCZYX'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.dims.order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a18d6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size = [test_img.physical_pixel_sizes.Y,test_img.physical_pixel_sizes.X]\n",
    "store_path = r\"E:\\Cores\\CellDIVE_ImageMerging\\Testing_CellDIVE_Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96962ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_data = test_img.get_image_data('YX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37a8711c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdeceb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_shapes = [\n",
    "    (test_image_data.shape[0],test_image_data.shape[1]),\n",
    "    (int(test_image_data.shape[0]/2),int(test_image_data.shape[1]/2)),\n",
    "    #(test_image_data.shape[0]/4,test_image_data.shape[1]/4),\n",
    "    #(test_image_data.shape[0]/8,test_image_data.shape[1]/8),\n",
    "    #(test_image_data.shape[0]/12,test_image_data.shape[1]/12),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a68dcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(47973, 62826), (23986, 31413)]\n"
     ]
    }
   ],
   "source": [
    "print(level_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f6b6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = OMEZarrWriter(\n",
    "    store = os.path.join(store_path,\"testing.zarr\"),\n",
    "    level_shapes=level_shapes,\n",
    "    dtype=test_image_data.dtype,\n",
    "    zarr_format=2,\n",
    "    channels=test_channel,\n",
    "    axes_names=[\"y\",\"x\"],\n",
    "    axes_types=[\"space\",\"space\"],\n",
    "    axes_units=[\"micrometer\",\"micrometer\"],\n",
    "    physical_pixel_size=pixel_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29420392",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.write_full_volume(test_image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72bfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioiozarr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
