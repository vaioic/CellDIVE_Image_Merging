{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "10ad4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioio import BioImage\n",
    "from bioio_ome_zarr.writers import Channel, OMEZarrWriter\n",
    "import dask.array as da\n",
    "from zarr.codecs import BloscCodec\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import Dict, List, Union\n",
    "from collections import defaultdict\n",
    "from Group_Files import group_ome_tiff_by_region, print_group_summary,extract_channel_marker_info,print_channel_marker_info\n",
    "import tempfile\n",
    "import os\n",
    "from ome_types import from_tiff, to_xml, from_xml\n",
    "from ome_types.model import Channel\n",
    "from ome_types.model import Image\n",
    "from ome_types.model import OME\n",
    "from ome_types.model import Pixels\n",
    "from ome_types.model import TiffData\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9ce9a",
   "metadata": {},
   "source": [
    "## Testing file grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to group OME-TIFF image files by region identifier.\n",
    "\n",
    "This module provides functionality to parse and group image files following\n",
    "the naming convention:\n",
    "prefix_mmddyyyy_S#_[1-15].0.4_R###_(channel)_(marker)_FINAL_suffix.ome.tif\n",
    "\"\"\"\n",
    "\n",
    "def group_ome_tiff_by_region(\n",
    "    directory: Union[str, Path],\n",
    "    return_type: str = \"dict\"\n",
    ") -> Union[Dict[str, List[str]], List[List[str]]]:\n",
    "    \"\"\"\n",
    "    Group OME-TIFF files by their region identifier (R###).\n",
    "    \n",
    "    This function searches for files matching the specified naming convention\n",
    "    and groups them by their region identifier. Only files containing 'FINAL'\n",
    "    in their name are included.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : str or Path\n",
    "        Path to the directory containing the OME-TIFF files\n",
    "    return_type : str, optional\n",
    "        Format of the return value. Either \"dict\" (default) or \"list\"\n",
    "        - \"dict\": Returns a dictionary with region IDs as keys\n",
    "        - \"list\": Returns a list of lists, one per region\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict or list\n",
    "        If return_type=\"dict\": Dictionary with region IDs (e.g., \"R001\") as keys\n",
    "            and lists of file paths as values\n",
    "        If return_type=\"list\": List of lists, where each inner list contains\n",
    "            file paths for one region\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Get groups as dictionary\n",
    "    >>> groups = group_ome_tiff_by_region(\"/path/to/images\", return_type=\"dict\")\n",
    "    >>> print(groups.keys())\n",
    "    dict_keys(['R000', 'R001', 'R002', ...])\n",
    "    \n",
    "    >>> # Get groups as list of lists\n",
    "    >>> groups = group_ome_tiff_by_region(\"/path/to/images\", return_type=\"list\")\n",
    "    >>> print(f\"Found {len(groups)} regions\")\n",
    "    Found 8 regions\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The regex pattern matches files with this structure:\n",
    "    - prefix: any characters (typically initials)\n",
    "    - date: mmddyyyy format\n",
    "    - sample: S followed by 1-2 digits (S1-S15)\n",
    "    - round: integer 1-15, followed by .0.4\n",
    "    - region: R followed by 3 digits (R000-R999)\n",
    "    - channel: DAPI, Cy3, Cy5, FITC, or Cy7\n",
    "    - marker: alphanumeric name\n",
    "    - must contain 'FINAL'\n",
    "    - suffix: AFR_F or _F\n",
    "    - extension: .ome.tif\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to Path object for easier handling\n",
    "    directory = Path(directory)\n",
    "    \n",
    "    if not directory.exists():\n",
    "        raise ValueError(f\"Directory does not exist: {directory}\")\n",
    "    \n",
    "    if not directory.is_dir():\n",
    "        raise ValueError(f\"Path is not a directory: {directory}\")\n",
    "    \n",
    "    # Regex pattern to match the file naming convention\n",
    "    # Pattern breakdown:\n",
    "    # ^(.+?)_ : prefix (non-greedy) followed by underscore\n",
    "    # (\\d{8})_ : date in mmddyyyy format\n",
    "    # (S\\d{1,2})_ : sample ID (S1 to S15)\n",
    "    # (\\d{1,2}\\.0\\.\\d+)_ : round number (1-15.0.4)\n",
    "    # (R\\d{3})_ : region identifier (R###)\n",
    "    # (DAPI|Cy3|Cy5|FITC|Cy7)_ : channel name\n",
    "    # ([A-Za-z0-9_]+)_ : marker name\n",
    "    # .*FINAL.* : must contain FINAL\n",
    "    # (AFR_F|_F) : suffix\n",
    "    # \\.ome\\.tif$ : file extension\n",
    "    \n",
    "    pattern = re.compile(\n",
    "        r'^(.+?)_'           # prefix\n",
    "        r'(\\d{8})_'          # date (mmddyyyy)\n",
    "        r'(S\\d{1,2})_'       # sample ID (S1-S15)\n",
    "        r'(\\d{1,2}\\.\\d+\\.\\d+)_'  # round (e.g., 1.0.1, 1.0.4, 15.0.4)\n",
    "        r'(R\\d{3})_'         # region (R###)\n",
    "        r'(DAPI|Cy3|Cy5|FITC|Cy7|FITC)_'  # channel name\n",
    "        r'(.+?)_'            # marker name (non-greedy)\n",
    "        r'.*FINAL.*'         # must contain FINAL\n",
    "        r'(AFR_F|_F)'        # suffix\n",
    "        r'\\.ome\\.tif$',      # extension\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store grouped files\n",
    "    region_groups = defaultdict(list)\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for file_path in directory.iterdir():\n",
    "        # Skip if not a file\n",
    "        if not file_path.is_file():\n",
    "            continue\n",
    "        \n",
    "        filename = file_path.name\n",
    "        \n",
    "        # Check if filename matches the pattern\n",
    "        match = pattern.match(filename)\n",
    "        \n",
    "        if match:\n",
    "            # Extract the region identifier (5th capture group)\n",
    "            region_id = match.group(5)\n",
    "            \n",
    "            # Add the full file path to the corresponding region group\n",
    "            region_groups[region_id].append(str(file_path))\n",
    "    \n",
    "    # Sort files within each group for consistent ordering\n",
    "    for region_id in region_groups:\n",
    "        region_groups[region_id].sort()\n",
    "    \n",
    "    # Return based on requested format\n",
    "    if return_type == \"dict\":\n",
    "        # Return as regular dict (sorted by region ID)\n",
    "        return dict(sorted(region_groups.items()))\n",
    "    elif return_type == \"list\":\n",
    "        # Return as list of lists (sorted by region ID)\n",
    "        return [region_groups[region_id] for region_id in sorted(region_groups.keys())]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid return_type: {return_type}. Must be 'dict' or 'list'\")\n",
    "\n",
    "\n",
    "def print_group_summary(groups: Union[Dict[str, List[str]], List[List[str]]]) -> None:\n",
    "    \"\"\"\n",
    "    Print a summary of the grouped files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    groups : dict or list\n",
    "        The output from group_ome_tiff_by_region()\n",
    "    \"\"\"\n",
    "    if isinstance(groups, dict):\n",
    "        print(f\"Found {len(groups)} region groups:\")\n",
    "        for region_id, files in groups.items():\n",
    "            print(f\"\\n{region_id}: {len(files)} files\")\n",
    "            for file_path in files:\n",
    "                print(f\"  - {Path(file_path).name}\")\n",
    "    elif isinstance(groups, list):\n",
    "        print(f\"Found {len(groups)} region groups:\")\n",
    "        for i, files in enumerate(groups):\n",
    "            print(f\"\\nGroup {i+1}: {len(files)} files\")\n",
    "            for file_path in files:\n",
    "                print(f\"  - {Path(file_path).name}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    \n",
    "    # Example 1: Get groups as dictionary\n",
    "    if len(sys.argv) > 1:\n",
    "        directory = sys.argv[1]\n",
    "    else:\n",
    "        directory = \"/mnt/user-data/uploads\"  # Default to uploaded files\n",
    "    \n",
    "    print(f\"Searching for OME-TIFF files in: {directory}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Get groups as dictionary\n",
    "        groups_dict = group_ome_tiff_by_region(directory, return_type=\"dict\")\n",
    "        print_group_summary(groups_dict)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\\nExample: Accessing files from a specific region:\")\n",
    "        if groups_dict:\n",
    "            first_region = list(groups_dict.keys())[0]\n",
    "            print(f\"\\nFiles in region {first_region}:\")\n",
    "            for file_path in groups_dict[first_region]:\n",
    "                print(f\"  {Path(file_path).name}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"\\nAlternative: Get groups as list of lists:\")\n",
    "        groups_list = group_ome_tiff_by_region(directory, return_type=\"list\")\n",
    "        print(f\"Total number of region groups: {len(groups_list)}\")\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada40c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test script to demonstrate the grouping function with example filenames\n",
    "from the uploaded image.\n",
    "\"\"\"\n",
    "\n",
    "# Create example filenames based on the uploaded image\n",
    "example_filenames = [\n",
    "    \"KK_10082025_S2_1.0.1_R000_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R000_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R001_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R001_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R002_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R002_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R003_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R003_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R004_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R004_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R005_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R005_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R006_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R006_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R007_20X_VHE_F.tif\",\n",
    "    \"KK_10082025_S2_1.0.1_R007_DAPI_AF_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R000_Cy3_iba1_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R000_Cy5_Neun_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R000_DAPI_FINAL_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R000_FITC_GFAP_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R001_Cy3_iba1_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R001_Cy5_Neun_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R001_DAPI_FINAL_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R001_FITC_GFAP_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R002_Cy3_iba1_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R002_Cy5_Neun_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R002_DAPI_FINAL_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R002_FITC_GFAP_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R003_Cy3_iba1_FINAL_AFR_F.ome.tif\",\n",
    "    \"KK_10082025_S2_1.0.4_R003_Cy5_Neun_FINAL_AFR_F.ome.tif\",\n",
    "]\n",
    "\n",
    "# Create a temporary directory and create empty files\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    print(f\"Creating test files in: {tmpdir}\\n\")\n",
    "    \n",
    "    # Create the test files\n",
    "    for filename in example_filenames:\n",
    "        filepath = Path(tmpdir) / filename\n",
    "        filepath.touch()\n",
    "    \n",
    "    print(f\"Created {len(example_filenames)} test files\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Test the grouping function with dictionary return type\n",
    "    print(\"\\n### TEST 1: Dictionary Return Type ###\\n\")\n",
    "    groups_dict = group_ome_tiff_by_region(tmpdir, return_type=\"dict\")\n",
    "    print_group_summary(groups_dict)\n",
    "    \n",
    "    # Show statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n### Statistics ###\")\n",
    "    print(f\"Total regions found: {len(groups_dict)}\")\n",
    "    for region_id, files in groups_dict.items():\n",
    "        print(f\"  {region_id}: {len(files)} files\")\n",
    "    \n",
    "    # Test with list return type\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n### TEST 2: List Return Type ###\\n\")\n",
    "    groups_list = group_ome_tiff_by_region(tmpdir, return_type=\"list\")\n",
    "    print(f\"Number of region groups: {len(groups_list)}\")\n",
    "    for i, group in enumerate(groups_list):\n",
    "        print(f\"\\nGroup {i+1}: {len(group)} files\")\n",
    "        for filepath in group[:3]:  # Show first 3 files\n",
    "            print(f\"  - {Path(filepath).name}\")\n",
    "        if len(group) > 3:\n",
    "            print(f\"  ... and {len(group) - 3} more files\")\n",
    "    \n",
    "    # Example: Process each group\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\n### Example: Processing Each Group ###\\n\")\n",
    "    for region_id, file_list in groups_dict.items():\n",
    "        print(f\"Processing region {region_id}:\")\n",
    "        print(f\"  - Found {len(file_list)} files\")\n",
    "        \n",
    "        # Example: Extract channel information\n",
    "        channels = set()\n",
    "        for filepath in file_list:\n",
    "            filename = Path(filepath).name\n",
    "            if \"DAPI\" in filename:\n",
    "                channels.add(\"DAPI\")\n",
    "            elif \"Cy3\" in filename:\n",
    "                channels.add(\"Cy3\")\n",
    "            elif \"Cy5\" in filename:\n",
    "                channels.add(\"Cy5\")\n",
    "            elif \"FITC\" in filename:\n",
    "                channels.add(\"FITC\")\n",
    "            elif \"Cy7\" in filename:\n",
    "                channels.add(\"Cy7\")\n",
    "        \n",
    "        print(f\"  - Channels present: {sorted(channels)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c88e42",
   "metadata": {},
   "source": [
    "## Testing reading in groups and merging into one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58dbf036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 region groups:\n",
      "\n",
      "R000: 6 files\n",
      "  - CG_10092025_S1_1.0.4_R000_Cy3_sLeX-AF594_FINAL_AFR_F.ome.tif\n",
      "  - CG_10092025_S1_1.0.4_R000_Cy5_ECad-AF647_FINAL_AFR_F.ome.tif\n",
      "  - CG_10092025_S1_1.0.4_R000_DAPI__FINAL_F.ome.tif\n",
      "  - CG_10092025_S1_1.0.4_R000_FITC_VVL-488_FINAL_AFR_F.ome.tif\n",
      "  - CG_10092025_S1_2.0.4_R000_Cy5_VIM-AF647_FINAL_AFR_F.ome.tif\n",
      "  - CG_10092025_S1_2.0.4_R000_FITC_AAL-FITC_FINAL_AFR_F.ome.tif\n",
      "Found channel/marker info for 1 regions:\n",
      "\n",
      "R000: 6 channels\n",
      "  - 1.0.4_Cy3_sLeX-AF594\n",
      "  - 1.0.4_Cy5_ECad-AF647\n",
      "  - 1.0.4_DAPI\n",
      "  - 1.0.4_FITC_VVL-488\n",
      "  - 2.0.4_Cy5_VIM-AF647\n",
      "  - 2.0.4_FITC_AAL-FITC\n"
     ]
    }
   ],
   "source": [
    "test_dir = r'E:\\Cores\\CellDIVE_ImageMerging\\Testing_CellDVIE_Input\\Trial2_10102025'\n",
    "groups_dict = group_ome_tiff_by_region(test_dir)\n",
    "print_group_summary(groups_dict)\n",
    "channel_dict = extract_channel_marker_info(test_dir)\n",
    "print_channel_marker_info(channel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b856ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop set up for reading through multiple regions\n",
    "for region_id, files in groups_dict.items():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(groups_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23cd2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = groups_dict['R000']\n",
    "channels = channel_dict['R000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80cafb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dic = [Channel(label=f\"{i}\",color=\"FF0000\") for i in channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = files[0]\n",
    "test_img = BioImage(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ffa75634",
   "metadata": {},
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "xmlns:schemaLocation: 'http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd' is not a valid URI, line 2, column 136 (<string>, line 2)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92mc:\\ProgramData\\anaconda3\\envs\\bioiozarr\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3701\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Cell \u001b[92mIn[93]\u001b[39m\u001b[92m, line 1\u001b[39m\n    ome_obj = from_tiff(r\"E:\\Cores\\CellDIVE_ImageMerging\\Testing_CellDVIE_Input\\Trial2_10102025\\CG_10092025_S1_1.0.4_R000_Cy3_sLeX-AF594_FINAL_AFR_F.ome.tif\")\n",
      "  File \u001b[92mc:\\ProgramData\\anaconda3\\envs\\bioiozarr\\Lib\\site-packages\\ome_types\\_conversion.py:161\u001b[39m in \u001b[95mfrom_tiff\u001b[39m\n    return from_xml(xml, validate=validate, parser_kwargs=parser_kwargs)\n",
      "  File \u001b[92mc:\\ProgramData\\anaconda3\\envs\\bioiozarr\\Lib\\site-packages\\ome_types\\_conversion.py:121\u001b[39m in \u001b[95mfrom_xml\u001b[39m\n    xml_2016 = ensure_2016(\n",
      "  File \u001b[92mc:\\ProgramData\\anaconda3\\envs\\bioiozarr\\Lib\\site-packages\\ome_types\\_conversion.py:479\u001b[39m in \u001b[95mensure_2016\u001b[39m\n    return ET.parse(normed_source)\n",
      "  File \u001b[92msrc/lxml/etree.pyx:3711\u001b[39m in \u001b[95mlxml.etree.parse\u001b[39m\n",
      "  File \u001b[92msrc/lxml/parser.pxi:2048\u001b[39m in \u001b[95mlxml.etree._parseDocument\u001b[39m\n",
      "  File \u001b[92msrc/lxml/parser.pxi:2066\u001b[39m in \u001b[95mlxml.etree._parseMemoryDocument\u001b[39m\n",
      "  File \u001b[92msrc/lxml/parser.pxi:1919\u001b[39m in \u001b[95mlxml.etree._parseDoc\u001b[39m\n",
      "  File \u001b[92msrc/lxml/parser.pxi:1944\u001b[39m in \u001b[95mlxml.etree._parseDoc_bytes\u001b[39m\n",
      "  File \u001b[92msrc/lxml/parser.pxi:1194\u001b[39m in \u001b[95mlxml.etree._BaseParser._parseDoc\u001b[39m\n",
      "  File \u001b[92msrc/lxml/parser.pxi:647\u001b[39m in \u001b[95mlxml.etree._ParserContext._handleParseResultDoc\u001b[39m\n",
      "  File \u001b[92msrc/lxml/parser.pxi:765\u001b[39m in \u001b[95mlxml.etree._handleParseResult\u001b[39m\n",
      "\u001b[36m  \u001b[39m\u001b[36mFile \u001b[39m\u001b[32msrc/lxml/parser.pxi:689\u001b[39m\u001b[36m in \u001b[39m\u001b[35mlxml.etree._raiseParseError\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:2\u001b[39m\n\u001b[31m    \u001b[39m\n    ^\n\u001b[31mXMLSyntaxError\u001b[39m\u001b[31m:\u001b[39m xmlns:schemaLocation: 'http://www.openmicroscopy.org/Schemas/OME/2016-06 http://www.openmicroscopy.org/Schemas/OME/2016-06/ome.xsd' is not a valid URI, line 2, column 136\n"
     ]
    }
   ],
   "source": [
    "ome_obj = from_tiff(r\"E:\\Cores\\CellDIVE_ImageMerging\\Testing_CellDVIE_Input\\Trial2_10102025\\CG_10092025_S1_1.0.4_R000_Cy3_sLeX-AF594_FINAL_AFR_F.ome.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20a9b7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Image(\n",
       "    id='Image:0',\n",
       "    pixels={'channels': [{'id': 'Channel:0', 'name': 'DAPI', 'color': Color('red', rgb=(255, 0, 0))}, {'id': 'Channel:1', 'name': 'GFAP', 'color': Color('lime', rgb=(0, 255, 0))}], 'id': 'Pixels:0', 'dimension_order': <Pixels_DimensionOrder.XYZCT: 'XYZCT'>, 'type': <PixelType.UINT16: 'uint16'>, 'size_x': 62826, 'size_y': 47973, 'size_z': 1, 'size_c': 2, 'size_t': 1, 'physical_size_x': 0.3, 'physical_size_y': 0.3},\n",
       " )]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ome_obj.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bc1b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_channel = [Channel(label=channels[0],color=\"FF0000\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7255906",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_two_files = files[0:2]\n",
    "test_two_channels = channels[0:2]\n",
    "test_two_channels_dic = [Channel(label=f\"{i}\",color=\"FF0000\") for i in test_two_channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "078bf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_two_images = list(map(BioImage,test_two_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f50373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_two_images_data = [img.get_image_data('YX') for img in test_two_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91b19be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 47973, 62826)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_two_images_data_stack = np.stack(test_two_images_data, axis=0)\n",
    "test_two_images_data_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a18d6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size = [0,test_img.physical_pixel_sizes.Y,test_img.physical_pixel_sizes.X]\n",
    "store_path = r\"E:\\Cores\\CellDIVE_ImageMerging\\Testing_CellDIVE_Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96962ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_data = test_img.get_image_data('YX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37a8711c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_two_images_data_stack.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bdeceb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_shapes = [\n",
    "    (2,test_image_data.shape[0],test_image_data.shape[1]),\n",
    "    (2,int(test_image_data.shape[0]/2),int(test_image_data.shape[1]/2)),\n",
    "    (2,int(test_image_data.shape[0]/4),int(test_image_data.shape[1]/4)),\n",
    "    (2,int(test_image_data.shape[0]/8),int(test_image_data.shape[1]/8)),\n",
    "    (2,int(test_image_data.shape[0]/12),int(test_image_data.shape[1]/12)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a68dcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 47973, 62826), (2, 23986, 31413), (2, 11993, 15706), (2, 5996, 7853), (2, 3997, 5235)]\n"
     ]
    }
   ],
   "source": [
    "print(level_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f6b6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = OMEZarrWriter(\n",
    "    store = os.path.join(store_path,\"testing_pyramid_two_channels.zarr\"),\n",
    "    level_shapes=level_shapes,\n",
    "    dtype=test_two_images_data_stack.dtype,\n",
    "    zarr_format=2,\n",
    "    channels=test_two_channels_dic,\n",
    "    axes_names=[\"c\",\"y\",\"x\"],\n",
    "    axes_types=[\"channel\",\"space\",\"space\"],\n",
    "    axes_units=[None,\"micrometer\",\"micrometer\"],\n",
    "    physical_pixel_size=pixel_size #if extra dimensions like time, channels, etc are added in, they need to be included in the list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "58a8b898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multiscales': [{'axes': [{'name': 'c', 'type': 'channel'},\n",
       "    {'name': 'y', 'type': 'space', 'unit': 'micrometer'},\n",
       "    {'name': 'x', 'type': 'space', 'unit': 'micrometer'}],\n",
       "   'datasets': [{'path': '0',\n",
       "     'coordinateTransformations': [{'type': 'scale',\n",
       "       'scale': [0.0, 0.325002437518281, 0.325002437518281]}]},\n",
       "    {'path': '1',\n",
       "     'coordinateTransformations': [{'type': 'scale',\n",
       "       'scale': [0.0, 0.6500184247087675, 0.650004875036562]}]},\n",
       "    {'path': '2',\n",
       "     'coordinateTransformations': [{'type': 'scale',\n",
       "       'scale': [0.0, 1.300036849417535, 1.300051135841304]}]},\n",
       "    {'path': '3',\n",
       "     'coordinateTransformations': [{'type': 'scale',\n",
       "       'scale': [0.0, 2.6002905161882075, 2.600102271682608]}]},\n",
       "    {'path': '4',\n",
       "     'coordinateTransformations': [{'type': 'scale',\n",
       "       'scale': [0.0, 3.9007610545570413, 3.9004017458497655]}]}],\n",
       "   'name': 'Image',\n",
       "   'version': '0.4'}],\n",
       " 'omero': {'id': 1,\n",
       "  'name': 'Image',\n",
       "  'version': '0.4',\n",
       "  'channels': [{'color': 'FF0000',\n",
       "    'coefficient': 1.0,\n",
       "    'active': True,\n",
       "    'label': '1.0.4_Cy3_sLeX-AF594',\n",
       "    'window': {'min': 0, 'max': 255, 'start': 0, 'end': 255},\n",
       "    'family': 'linear',\n",
       "    'inverted': False},\n",
       "   {'color': 'FF0000',\n",
       "    'coefficient': 1.0,\n",
       "    'active': True,\n",
       "    'label': '1.0.4_Cy5_ECad-AF647',\n",
       "    'window': {'min': 0, 'max': 255, 'start': 0, 'end': 255},\n",
       "    'family': 'linear',\n",
       "    'inverted': False}],\n",
       "  'rdefs': {'defaultT': 0, 'defaultZ': 0, 'model': 'color'}}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer.preview_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "29420392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\bioiozarr\\Lib\\site-packages\\bioio_ome_zarr\\writers\\ome_zarr_writer.py:390: PerformanceWarning: The input Dask array will be rechunked along axis 1 with chunk size 3997, but a chunk size divisible by 1602 is required for Dask to write safely to the Zarr array <Array file://E:/Cores/CellDIVE_ImageMerging/Testing_CellDIVE_Output/testing_pyramid_two_channels.zarr/4 shape=(2, 3997, 5235) dtype=uint16>. To avoid risk of data loss when writing to this Zarr array, set the \"array.chunk-size\" configuration parameter to at least the size in bytes of a single on-disk chunk (or shard) of the Zarr array, which in this case is 16772940 bytes. E.g., dask.config.set({\"array.chunk-size\": 16772940})\n",
      "  ops.append(da.to_zarr(src, self.datasets[level_index], compute=False))\n"
     ]
    }
   ],
   "source": [
    "writer.write_full_volume(test_two_images_data_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72bfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioiozarr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
